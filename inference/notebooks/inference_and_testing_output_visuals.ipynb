{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torchvision\n",
    "\n",
    "torchvision.disable_beta_transforms_warning()\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "if os.getcwd().split(\"/\")[-1] == \"notebooks\":\n",
    "    os.chdir(\"../..\")\n",
    "\n",
    "from inference.inference_model_avg import SFDInferenceModelAvg\n",
    "from inference.image_generation.image_generator import ImageGenerator\n",
    "from inference.utils import concatenate_2x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Has found /embds_pooled.h5 files, will only use /embds_pooled.h5\n",
      "has_pooled_embds set to True\n",
      "Has found /embds.h5 files, will only use /embds_pooled.h5\n",
      "has_embds set to True\n",
      "Initializing Properties class...\n",
      "property_to_pid :  {'A blond girl': 0, 'A brunette girl': 1, 'with blue eyes': 2, 'with brown eyes': 3, 'walking down the street': 4, 'walking in the rain': 5, 'at a market': 6, 'sitting at a cafe': 7, 'sitting in a bar': 8, 'on horseback in the forest': 9, 'on horseback across a plain': 10, 'at the beach': 11, 'on a boat': 12, 'driving a blue car': 13, 'driving a red car': 14, 'wearing a blue t-shit': 15, 'wearing a black t-shit': 16, 'wearing a red t-shit': 17, 'and a hat': 18, 'and a baseball cap': 19, 'holding a coffee': 20, 'holding a coca-cola': 21, 'holding a gun': 22, 'smoking a cigarette': 23, 'looking to the left': 24, 'looking to the right': 25, 'looking in front of her': 26, 'looking behind her': 27}\n",
      "category_to_cid :  {'hair': 0, 'eyes': 1, 'situration': 2, 't_shirt': 3, 'hat': 4, 'action': 5, 'pose': 6}\n",
      "cid_to_pids :  {0: [0, 1], 1: [2, 3], 2: [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], 3: [15, 16, 17], 4: [18, 19], 5: [20, 21, 22, 23], 6: [24, 25, 26, 27]}\n",
      "n_properties :  28\n",
      "n_categories :  7\n",
      "Properties class initialized.\n",
      "self.properties =  {'hair': 0, 'eyes': 1, 'situration': 2, 't_shirt': 3, 'hat': 4, 'action': 5, 'pose': 6}\n",
      "Initializing SameId class...\n",
      "categories_never_same :  []\n",
      "n_pid_never_same :  0\n",
      "cid_never_same :  []\n",
      "pid_never_same :  []\n",
      "cid_to_pid_same :  {0: [0], 1: [2], 2: [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], 3: [15, 16, 17], 4: [18, 19], 5: [20, 21, 22, 23], 6: [24, 25, 26, 27]}\n",
      "tid_same :  [7, 9, 12, 24, 38, 39, 42, 50, 56, 58, 69, 76, 86, 96, 99, 110, 116, 125, 129, 133, 136, 138, 140, 141, 145, 151, 154, 160, 165, 167, 179, 181, 182, 188, 189, 198, 201, 204, 206, 207, 209, 219, 228, 232, 256, 257, 260, 261, 266, 268, 273, 276, 277, 278, 279, 289, 292, 302, 310, 311, 312, 315, 319, 331, 332, 339, 343, 355, 356, 368, 372, 378, 392, 394, 395, 396, 398, 404, 407, 408, 411, 426, 430, 431, 438, 442, 443, 444, 465, 467, 476, 480, 483, 488, 490, 492, 493, 494, 495, 496, 510, 515, 517, 519, 521, 527, 532, 542, 543, 546, 547, 551, 552, 567, 574, 579, 583, 600, 606, 611, 616, 617, 619, 623, 627, 629, 630, 634, 653, 654, 668, 684, 685, 688, 690, 697, 700, 706, 708, 711, 714, 717, 718, 720, 721, 722, 726, 731, 735, 750, 755, 765, 767, 771, 780, 781, 790, 797, 799, 804, 805, 806, 813, 818, 819, 820, 830, 832, 833, 840, 841, 848, 865, 868, 870, 872, 877, 884, 886, 893, 895, 897, 898, 903, 919, 920, 922, 930, 939, 941, 946, 954, 963, 979, 983, 984, 989, 991, 993, 1000, 1002, 1006, 1014, 1019, 1022, 1024, 1028, 1032, 1037, 1045, 1048, 1049, 1055, 1056, 1061, 1063, 1076, 1099, 1100, 1107, 1112, 1113, 1116, 1119, 1123, 1124, 1127, 1129, 1131, 1134, 1135, 1136, 1137, 1141, 1146, 1154, 1161, 1166, 1180, 1184, 1185, 1189, 1204, 1208, 1221, 1224, 1230, 1235, 1237, 1239, 1240, 1244, 1246, 1247, 1251, 1254, 1256, 1258, 1262, 1272, 1273, 1277, 1279, 1298, 1302, 1304, 1306, 1313, 1315, 1322, 1323, 1325, 1332, 1344, 1345, 1348, 1349, 1350, 1356, 1358, 1366, 1385, 1388, 1390, 1391, 1393, 1413, 1416, 1420, 1423, 1438, 1451, 1454, 1459, 1465, 1467, 1469, 1471, 1483, 1485, 1490, 1492, 1495, 1499]\n",
      "304 prompts are the same id, over a total of 1500 prompts.\n",
      "SameId class initialized.\n",
      "self.mask_reduced =  tensor([[1, 0, 0,  ..., 0, 0, 0],\n",
      "        [1, 0, 1,  ..., 0, 0, 1],\n",
      "        [0, 1, 0,  ..., 1, 0, 0],\n",
      "        ...,\n",
      "        [0, 1, 1,  ..., 0, 1, 0],\n",
      "        [0, 1, 0,  ..., 1, 0, 0],\n",
      "        [1, 0, 1,  ..., 0, 0, 0]], dtype=torch.int16)\n",
      "self.mask_reduced shape =  torch.Size([1500, 28])\n",
      "Initialised dataset with 28 properties and 1500 prompts.\n",
      "dim_x = 1366016\n",
      "Setting up MAX_MIN normalization\n",
      "Found embds_max.json\n",
      "Checking that the reduced mask matches the prompts...\n",
      "Decoder initialized\n",
      "Decoder(\n",
      "  (Y): Embedding(29, 10, padding_idx=0)\n",
      "  (linear): Linear(in_features=280, out_features=1366016, bias=True)\n",
      "  (activation): LeakyReLU(negative_slope=0.2)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "sdf_inference = SFDInferenceModelAvg(\"results/training_cigarettes_ouns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------------+-----------------------------+------------------------+--------------------+---------------------+-------------------------+\n",
      "| hair            | eyes            | situration                  | t_shirt                | hat                | action              | pose                    |\n",
      "+-----------------+-----------------+-----------------------------+------------------------+--------------------+---------------------+-------------------------+\n",
      "| A blond girl    | with blue eyes  | walking down the street     | wearing a blue t-shit  | and a hat          | holding a coffee    | looking to the left     |\n",
      "| A brunette girl | with brown eyes | walking in the rain         | wearing a black t-shit | and a baseball cap | holding a coca-cola | looking to the right    |\n",
      "|                 |                 | at a market                 | wearing a red t-shit   |                    | holding a gun       | looking in front of her |\n",
      "|                 |                 | sitting at a cafe           |                        |                    | smoking a cigarette | looking behind her      |\n",
      "|                 |                 | sitting in a bar            |                        |                    |                     |                         |\n",
      "|                 |                 | on horseback in the forest  |                        |                    |                     |                         |\n",
      "|                 |                 | on horseback across a plain |                        |                    |                     |                         |\n",
      "|                 |                 | at the beach                |                        |                    |                     |                         |\n",
      "|                 |                 | on a boat                   |                        |                    |                     |                         |\n",
      "|                 |                 | driving a blue car          |                        |                    |                     |                         |\n",
      "|                 |                 | driving a red car           |                        |                    |                     |                         |\n",
      "+-----------------+-----------------+-----------------------------+------------------------+--------------------+---------------------+-------------------------+\n"
     ]
    }
   ],
   "source": [
    "sdf_inference.display_properties()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx1 =  15\n",
      "prompt1 =  A blond girl, with brown eyes, sitting in a bar, wearing a blue t-shit, and a baseball cap, holding a gun, looking to the left\n",
      "idx2 =  17\n",
      "prompt2 =  A blond girl, with brown eyes, walking down the street, wearing a red t-shit, and a baseball cap, holding a gun, looking in front of her\n"
     ]
    }
   ],
   "source": [
    "idx1, prompt1 = sdf_inference.search_idx_prompt(\n",
    "    [\n",
    "        \"A blond girl\",\n",
    "        \"with brown eyes\",\n",
    "        \"sitting in a bar\",\n",
    "        \"wearing a blue t-shit\",\n",
    "        \"and a baseball cap\",\n",
    "        \"holding a gun\",\n",
    "        \"looking to the left\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "print(\"idx1 = \", idx1)\n",
    "print(\"prompt1 = \", prompt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pipeline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/large_turbo/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Fetching 2 files: 100%|██████████| 2/2 [00:00<00:00, 29746.84it/s]\n",
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:47<00:00, 23.75s/it]\n",
      "Loading pipeline components...:  33%|███▎      | 3/9 [00:00<00:00, 20.27it/s]You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n",
      "Loading pipeline components...: 100%|██████████| 9/9 [00:12<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline loaded.\n"
     ]
    }
   ],
   "source": [
    "# load the diffusion model\n",
    "\n",
    "image_generator = ImageGenerator(simulated=False, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:06<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved in image_blond_bar_holding_gun.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:06<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved in image_blond_street_holding_gun.png\n"
     ]
    }
   ],
   "source": [
    "# generate original images\n",
    "\n",
    "image_generator.generate_image_from_prompt(prompt=prompt1, image_name=\"image_blond_bar_holding_gun.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a new embedding\n",
    "embd1 = sdf_inference.get_x(idx=idx1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embd_1, pooled_embd_1 = sdf_inference.overwrite_full_embedding(embd1, idx=idx1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embds =  torch.Size([1, 333, 4096])\n",
      "pooled_embd_1 =  torch.Size([1, 2048])\n"
     ]
    }
   ],
   "source": [
    "print(\"embds = \", embd_1.shape)\n",
    "print(\"pooled_embd_1 = \", pooled_embd_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:03<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved in image_blond_bar_holding_gun_reconstructed.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:03<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved in image_blond_street_holding_gun_reconstructed.png\n"
     ]
    }
   ],
   "source": [
    "image_generator.generate_image_from_embd(\n",
    "   prompt_embeds=embd_1.detach(),\n",
    "    pooled_prompt_embeds=pooled_embd_1.detach(),\n",
    "    image_name=\"image_blond_bar_holding_gun_reconstructed.png\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  0,  4,  0,  0,  0,  0,  9,  0,  0,  0,  0,  0,  0, 16,  0,  0,\n",
      "          0, 20,  0, 22,  0,  0, 25,  0,  0,  0]])\n",
      "tensor([[ 0,  1,  0,  4,  5,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 18,\n",
      "          0, 20,  0, 22,  0,  0,  0,  0, 27,  0]])\n",
      "tensor(0)\n",
      "tensor([[ 0,  1,  0,  4,  5,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 18,\n",
      "          0, 20, 21,  0,  0,  0,  0,  0, 27,  0]])\n"
     ]
    }
   ],
   "source": [
    "custom_mask1 = sdf_inference.decoder.mask_arange[idx1 : idx1 + 1, :]\n",
    "print(custom_mask1)\n",
    "\n",
    "custom_mask1[0,21] = 0\n",
    "custom_mask1[0,20] = 21\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:03<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved in image_brune_street_insert_cola_reconstructed.png\n"
     ]
    }
   ],
   "source": [
    "embds1_by_hand = sdf_inference.decoder.Y(\n",
    "    custom_mask1\n",
    ")\n",
    "embds1_by_hand = sdf_inference.decoder.activation(embds1_by_hand)\n",
    "embds1_by_hand = embds1_by_hand.reshape(embds1_by_hand.shape[0], -1)\n",
    "embds1_by_hand = sdf_inference.decoder.linear(embds1_by_hand)\n",
    "\n",
    "\n",
    "embd_1, pooled_embd_1 = sdf_inference.overwrite_full_embedding(embds1_by_hand, idx=idx1)\n",
    "\n",
    "image_generator.generate_image_from_embd(\n",
    "    prompt_embeds=embd_1.detach(),\n",
    "    pooled_prompt_embeds=pooled_embd_1.detach(),\n",
    "    image_name=\"image_brune_street_insert_cola_reconstructed.png\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "large_turbo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
